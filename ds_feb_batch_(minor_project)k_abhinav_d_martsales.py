# -*- coding: utf-8 -*-
"""DS-FEB BATCH (MINOR PROJECT)K.ABHINAV D-MartSales

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wP9-4dpcm0EEfXRJ9X4EtxR6ZWvgKgf5
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load datasets
train = pd.read_csv('/content/train (1).csv')
test = pd.read_csv('/content/test (1).csv')

# Check shapes
print(f"Training data shape: {train.shape}")
print(f"Testing data shape: {test.shape}")

# Display first few rows
train.head()

# Combine for consistent preprocessing
train['source'] = 'train'
test['source'] = 'test'
combined = pd.concat([train, test], ignore_index=True)

# Handle missing values
combined['Item_Weight'].fillna(combined['Item_Weight'].mean(), inplace=True)
combined['Outlet_Size'].fillna(combined['Outlet_Size'].mode()[0], inplace=True)

# Fix inconsistent categories
combined['Item_Fat_Content'] = combined['Item_Fat_Content'].replace({
    'LF': 'Low Fat',
    'low fat': 'Low Fat',
    'reg': 'Regular'
})

# Feature engineering
combined['Item_Type_Combined'] = combined['Item_Identifier'].apply(lambda x: x[:2])
combined['Years_Operating'] = 2013 - combined['Outlet_Establishment_Year']

# Sales distribution
plt.figure(figsize=(10,6))
sns.histplot(train['Item_Outlet_Sales'], bins=50, kde=True)
plt.title('Item Outlet Sales Distribution')
plt.show()

# Correlation heatmap
plt.figure(figsize=(12,8))
corr = train.corr(numeric_only=True)
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Categorical features vs sales
plt.figure(figsize=(12,6))
sns.boxplot(x='Outlet_Type', y='Item_Outlet_Sales', data=train)
plt.title('Sales by Outlet Type')
plt.xticks(rotation=45)
plt.show()

from sklearn.preprocessing import LabelEncoder, StandardScaler

# Encode categorical variables
le = LabelEncoder()
combined['Outlet'] = le.fit_transform(combined['Outlet_Identifier'])

categorical_cols = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size',
                   'Outlet_Location_Type', 'Outlet_Type', 'Item_Type_Combined']

# Check if all categorical columns exist in the DataFrame
missing_cols = [col for col in categorical_cols if col not in combined.columns]

# Print missing columns for debugging
if missing_cols:
    print(f"Missing columns: {missing_cols}")
else:
    combined = pd.get_dummies(combined, columns=categorical_cols)

# Split back into train and test
train_processed = combined[combined['source'] == 'train']
test_processed = combined[combined['source'] == 'test']

# Define features and target
features = [col for col in train_processed.columns if col not in ['Item_Outlet_Sales', 'source', 'Item_Identifier', 'Outlet_Identifier']]
X_train = train_processed[features]
y_train = train_processed['Item_Outlet_Sales']
X_test = test_processed[features]

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score

# Initialize model
model = RandomForestRegressor(n_estimators=200, random_state=42)

# Cross-validation
scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')
print(f"Average RMSE: {-scores.mean():.2f}")

# Train final model
model.fit(X_train, y_train)

# Feature importance
feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)
feat_importances.nlargest(10).plot(kind='barh')
plt.title('Top 10 Important Features')
plt.show()

# Predict on test data
test_predictions = model.predict(X_test)

# Prepare submission
submission = pd.DataFrame({
    'Item_Identifier': test['Item_Identifier'],
    'Outlet_Identifier': test['Outlet_Identifier'],
    'Item_Outlet_Sales': test_predictions
})

# Save predictions
submission.to_csv('submission.csv', index=False)

# Option 1: Display predictions directly in your notebook/console
print(test_predictions[:10])  # Show first 10 predictions

# Option 2: View the submission DataFrame
print(submission.head())  # Shows IDs with predicted sales

# Option 3: Save to file and download/examine
submission.to_csv('BigMart_Predictions.csv', index=False)

# Generate predictions for TRAINING data (for validation)
train_predictions = model.predict(X_train)

# Generate predictions for TEST data (final submission)
test_predictions = model.predict(X_test)

# Create DataFrames with predictions
train_results = train.copy()
train_results['Predicted_Sales'] = train_predictions

test_results = test.copy()
test_results['Predicted_Sales'] = test_predictions

# Print sample of training predictions
print("TRAINING DATA PREDICTIONS (First 10 rows)")
print(train_results[['Item_Identifier', 'Outlet_Identifier',
                    'Item_Outlet_Sales', 'Predicted_Sales']].head(10))

# Generate predictions for TRAINING data (for validation)
train_predictions = model.predict(X_train)

# Generate predictions for TEST data (final submission)
test_predictions = model.predict(X_test)

# Create DataFrames with predictions
train_results = train.copy()
train_results['Predicted_Sales'] = train_predictions

test_results = test.copy()
test_results['Predicted_Sales'] = test_predictions

# Print sample of training predictions
print("TRAINING DATA PREDICTIONS (First 10 rows)")
print(train_results[['Item_Identifier', 'Outlet_Identifier',
                    'Item_Outlet_Sales', 'Predicted_Sales']].head(10))

# Generate predictions for TRAINING data (for validation)
train_predictions = model.predict(X_train)

# Generate predictions for TEST data (final submission)
test_predictions = model.predict(X_test)

# Create DataFrames with predictions
train_results = train.copy()
train_results['Predicted_Sales'] = train_predictions

test_results = test.copy()
test_results['Predicted_Sales'] = test_predictions

# Print sample of training predictions
print("TRAINING DATA PREDICTIONS (First 10 rows)")
print(train_results[['Item_Identifier', 'Outlet_Identifier',
                    'Item_Outlet_Sales', 'Predicted_Sales']].head(10))

# Generate predictions for TRAINING data (for validation)
train_predictions = model.predict(X_train)

# Generate predictions for TEST data (final submission)
test_predictions = model.predict(X_test)

# Create DataFrames with predictions
train_results = train.copy()
train_results['Predicted_Sales'] = train_predictions

test_results = test.copy()
test_results['Predicted_Sales'] = test_predictions

# Print sample of training predictions
print("TRAINING DATA PREDICTIONS (First 10 rows)")
print(train_results[['Item_Identifier', 'Outlet_Identifier',
                    'Item_Outlet_Sales', 'Predicted_Sales']].head(10))

# Print sample of test predictions
print("\nTEST DATA PREDICTIONS (First 10 rows)")
print(test_results[['Item_Identifier', 'Outlet_Identifier', 'Predicted_Sales']].head(10))